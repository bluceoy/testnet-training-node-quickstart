基于您提供的 Notebook 分析报告，当前的训练配置存在**致命缺陷**，直接导致模型无法有效学习。最核心的问题在于**训练步数远少于预热步数**（Warmup Steps），这意味着训练会在学习率还没升上来之前就结束了。

以下是详细的问题分析以及针对不同模型尺寸的**参数调整具体实施方案**。

---

### 🔴 核心问题诊断 (为什么现在的设置不行？)

1.  **数学上的逻辑错误 (Fatal Error)**：
    *   **现状**：数据只有 78 条。Batch Size=8。训练 1 个 Epoch。
    *   **计算**：总训练步数 = 78 / 8 ≈ **10 步**。
    *   **冲突**：代码中硬编码了 `warmup_steps = 100`。
    *   **后果**：训练总共只有 10 步，但系统设定前 100 步是热身阶段（学习率从 0 慢慢增加）。**结果是训练结束时，学习率可能只达到了目标值的 10%，模型几乎什么都没学到。**

2.  **数据量过小**：
    *   只有 78 条数据，跑 1 个 Epoch (轮次) 意味着模型只看了一遍数据，完全不足以进行微调。

3.  **LoRA 覆盖不足**：
    *   当前只训练了 `q_proj` 和 `v_proj`，对于小样本数据，需要训练更多的模块才能让模型适配。

---

### ✅ 参数调整实施方案

请按照以下步骤修改您的两个文件：`training_args.yaml` 和 `demo.py`。

#### 第一步：修改 `training_args.yaml`
此文件控制训练的轮次、Batch大小和 LoRA 的结构参数。

**修改建议：** 增加 Epochs (轮次)，调整 LoRA Rank。

```yaml
# 建议将原有内容替换为以下优化后的配置：

Qwen/Qwen2.5-0.5B-Instruct:
  gradient_accumulation_steps: 4    # 稍微降低累积步数，增加更新频率
  lora_alpha: 32                    # Alpha 通常设置为 Rank 的 2倍
  lora_dropout: 0.05                # 降低 Dropout 防止欠拟合
  lora_rank: 16                     # 0.5B 模型较小，增加 Rank 提升容量
  num_train_epochs: 5               # 数据少，必须多跑几轮 (从 1 改为 5)
  per_device_train_batch_size: 2    # 显存允许的话，稍微增大 Batch

Qwen/Qwen2.5-1.5B-Instruct:
  gradient_accumulation_steps: 4
  lora_alpha: 16
  lora_dropout: 0.05
  lora_rank: 8
  num_train_epochs: 4               # 1.5B 模型跑 4 轮
  per_device_train_batch_size: 1

Qwen/Qwen2.5-7B-Instruct:
  gradient_accumulation_steps: 4
  lora_alpha: 16
  lora_dropout: 0.05
  lora_rank: 8
  num_train_epochs: 3               # 7B 模型较大，跑 3 轮通常足够
  per_device_train_batch_size: 1
```

---

#### 第二步：修改 `demo.py`
此文件包含硬编码的参数，必须修改以修复 Warmup 错误并优化学习率。

**修改位置 1：优化 LoRA 目标模块**
找到 `train_lora` 函数中的 `lora_config` 部分：

```python
    # 原代码
    # target_modules=["q_proj", "v_proj"],

    # 修改为 (覆盖更多注意力层和输出层，提升效果)：
    target_modules=[
        "q_proj",
        "k_proj",
        "v_proj",
        "o_proj",
        "gate_proj", # 可选，显存够可以加上
        "up_proj",   # 可选
        "down_proj", # 可选
    ],
```

**修改位置 2：修复 Warmup、学习率和上下文长度**
找到 `train_lora` 函数中的 `SFTConfig` 定义部分：

```python
    # 找到这部分代码并修改
    training_args = SFTConfig(
        # ... 其他参数保持从 yaml 读取 ...

        # [修改] 核心修复：将 100 改为 5。或者使用 ratio 0.1
        warmup_steps=5, 

        # [修改] 降低学习率。对于小数据，2e-4 太大容易震荡，建议 5e-5 或 1e-4
        learning_rate=5e-5, 

        bf16=True,
        logging_steps=1, # [修改] 数据少，建议每 1 步就打印日志，不然看不到进度
        output_dir="outputs",
        optim="paged_adamw_8bit",
        remove_unused_columns=False,
        num_train_epochs=training_args.num_train_epochs,
        
        # [修改] 优化显存。分析显示99%数据小于484 token，1024 足够了
        max_seq_length=1024, 
    )
```

---

### 📊 优化前后的对比预期

| 指标 | 修改前 (当前状态) | 修改后 (优化建议) | 作用 |
| :--- | :--- | :--- | :--- |
| **总训练步数** | ~10 步 | ~50 到 80 步 | 让模型有足够的机会看到数据 |
| **热身步数** | 100 步 (严重错误) | 5 步 | 确保学习率能正常达到峰值并生效 |
| **训练轮次** | 1 Epoch | 3-5 Epochs | 小样本数据需要多轮次强化记忆 |
| **学习率** | 2e-4 (可能过大) | 5e-5 (更稳健) | 防止在小数据集上过拟合或震荡 |
| **LoRA范围** | 仅 Q, V | Q, K, V, O | 提升模型理解指令的能力 |
| **上下文长度**| 2048 | 1024 | 节省显存，加快训练速度 |

**总结操作：**
1. 打开 `training_args.yaml`，增加 `num_train_epochs` 并调整 `rank`。
2. 打开 `demo.py`，将 `warmup_steps=100` 改为 `5`，并扩展 `target_modules`。